{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_detection\n",
    "import imageio\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3)\n",
    "\n",
    "input_path = \"input/\"\n",
    "output = \"output_face_detection/\"\n",
    "output_roi = \"output_roi/\"\n",
    "imgs_path = sorted(os.listdir(input_path))\n",
    "\n",
    "\n",
    "for i, img in enumerate(tqdm(imgs_path)):\n",
    "    \n",
    "    img_path = img\n",
    "    fig, ax = plt.subplots(1)\n",
    "    img = imageio.imread(input_path+img)\n",
    "    w, h, _ = img.shape\n",
    "\n",
    "    img_detections = detector.detect(img)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    for j, faces_detected in enumerate(img_detections):\n",
    "        x1, y1, x2, y2, _ = faces_detected\n",
    "        x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)\n",
    "        ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=2))\n",
    "        imageio.imwrite(f\"{output_roi+img_path[:-4]}_output_{j}_roi.png\",img[int(y1):int(y2), int(x1): int(x2)])\n",
    "    \n",
    "    plt.savefig(f\"{output+img_path[:-4]}_output.png\")\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skin classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import dlib\n",
    "import os\n",
    "import argparse\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"output_roi/\"\n",
    "img_names = sorted(os.listdir(input_path))\n",
    "\n",
    "output_path = \"output_roi_skin_classification/\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "bestW_7_path = \"../skin_color_classification/fairface_official_weights/res34_fair_align_multi_7_20190809.pt\"\n",
    "model_fair_7 = torchvision.models.resnet34(pretrained=True)\n",
    "model_fair_7.fc = nn.Linear(model_fair_7.fc.in_features, 18)\n",
    "model_fair_7.load_state_dict(torch.load(bestW_7_path))\n",
    "model_fair_7 = model_fair_7.to(device)\n",
    "model_fair_7.eval()\n",
    "\n",
    "\n",
    "bestW_4_path = \"../skin_color_classification/fairface_official_weights/res34_fair_align_multi_4_20190809.pt\"\n",
    "model_fair_4 = resnet34(pretrained=True)\n",
    "model_fair_4.fc = nn.Linear(model_fair_4.fc.in_features, 18)\n",
    "model_fair_4.load_state_dict(torch.load(bestW_4_path))\n",
    "model_fair_4.to(device)\n",
    "model_fair_4.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "# img pth of face images\n",
    "face_names = []\n",
    "\n",
    "\n",
    "# list within a list. Each sublist contains scores for all races. \n",
    "# Take max for predicted race\n",
    "race_scores_fair = []\n",
    "gender_scores_fair = []\n",
    "age_scores_fair = []\n",
    "race_preds_fair = []\n",
    "gender_preds_fair = []\n",
    "age_preds_fair = []\n",
    "race_scores_fair_4 = []\n",
    "race_preds_fair_4 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, img_name in enumerate(tqdm(img_names)):\n",
    "\n",
    "    image = dlib.load_rgb_image(input_path+img_name)\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    image = trans(image)\n",
    "    image = image.view(1, 3, 224, 224)  # reshape image to match model dimensions (1 batch size)\n",
    "    image = image.to(device)\n",
    "    \n",
    "    # fair 7 class\n",
    "    outputs = model_fair_7(image)\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    outputs = np.squeeze(outputs)\n",
    "\n",
    "    race_outputs = outputs[:7]\n",
    "    gender_outputs = outputs[7:9]\n",
    "    age_outputs = outputs[9:18]\n",
    "\n",
    "    race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "    gender_score = np.exp(gender_outputs) / np.sum(np.exp(gender_outputs))\n",
    "    age_score = np.exp(age_outputs) / np.sum(np.exp(age_outputs))\n",
    "\n",
    "    race_pred = np.argmax(race_score)\n",
    "    gender_pred = np.argmax(gender_score)\n",
    "    age_pred = np.argmax(age_score)\n",
    "\n",
    "    race_scores_fair.append(race_score)\n",
    "    gender_scores_fair.append(gender_score)\n",
    "    age_scores_fair.append(age_score)\n",
    "\n",
    "    race_preds_fair.append(race_pred)\n",
    "    gender_preds_fair.append(gender_pred)\n",
    "    age_preds_fair.append(age_pred)\n",
    "\n",
    "\n",
    "\n",
    "    # fair 4 class\n",
    "    outputs = model_fair_4(image)\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    outputs = np.squeeze(outputs)\n",
    "\n",
    "    race_outputs = outputs[:4]\n",
    "    race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "    race_pred = np.argmax(race_score)\n",
    "\n",
    "    race_scores_fair_4.append(race_score)\n",
    "    race_preds_fair_4.append(race_pred)    \n",
    "    \n",
    "\n",
    "    plt.savefig(f\"{output_path+img_name[:-4]}_output.png\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame([face_names,\n",
    "                    race_preds_fair,\n",
    "                    race_preds_fair_4,\n",
    "                    gender_preds_fair,\n",
    "                    age_preds_fair,\n",
    "                    race_scores_fair, race_scores_fair_4,\n",
    "                    gender_scores_fair,\n",
    "                    age_scores_fair, ]).T\n",
    "\n",
    "\n",
    "result.columns = ['face_name_align',\n",
    "                'race_preds_fair',\n",
    "                'race_preds_fair_4',\n",
    "                'gender_preds_fair',\n",
    "                'age_preds_fair',\n",
    "                'race_scores_fair',\n",
    "                'race_scores_fair_4',\n",
    "                'gender_scores_fair',\n",
    "                'age_scores_fair']\n",
    "\n",
    "\n",
    "result.loc[result['race_preds_fair'] == 0, 'race'] = 'White'\n",
    "result.loc[result['race_preds_fair'] == 1, 'race'] = 'Black'\n",
    "result.loc[result['race_preds_fair'] == 2, 'race'] = 'Latino_Hispanic'\n",
    "result.loc[result['race_preds_fair'] == 3, 'race'] = 'East Asian'\n",
    "result.loc[result['race_preds_fair'] == 4, 'race'] = 'Southeast Asian'\n",
    "result.loc[result['race_preds_fair'] == 5, 'race'] = 'Indian'\n",
    "result.loc[result['race_preds_fair'] == 6, 'race'] = 'Middle Eastern'\n",
    "\n",
    "# race fair 4\n",
    "result.loc[result['race_preds_fair_4'] == 0, 'race4'] = 'White'\n",
    "result.loc[result['race_preds_fair_4'] == 1, 'race4'] = 'Black'\n",
    "result.loc[result['race_preds_fair_4'] == 2, 'race4'] = 'Asian'\n",
    "result.loc[result['race_preds_fair_4'] == 3, 'race4'] = 'Indian'\n",
    "\n",
    "# gender\n",
    "result.loc[result['gender_preds_fair'] == 0, 'gender'] = 'Male'\n",
    "result.loc[result['gender_preds_fair'] == 1, 'gender'] = 'Female'\n",
    "\n",
    "# age\n",
    "result.loc[result['age_preds_fair'] == 0, 'age'] = '0-2'\n",
    "result.loc[result['age_preds_fair'] == 1, 'age'] = '3-9'\n",
    "result.loc[result['age_preds_fair'] == 2, 'age'] = '10-19'\n",
    "result.loc[result['age_preds_fair'] == 3, 'age'] = '20-29'\n",
    "result.loc[result['age_preds_fair'] == 4, 'age'] = '30-39'\n",
    "result.loc[result['age_preds_fair'] == 5, 'age'] = '40-49'\n",
    "result.loc[result['age_preds_fair'] == 6, 'age'] = '50-59'\n",
    "result.loc[result['age_preds_fair'] == 7, 'age'] = '60-69'\n",
    "result.loc[result['age_preds_fair'] == 8, 'age'] = '70+'\n",
    "\n",
    "\n",
    "save_predictions = \"out.csv\"\n",
    "result[['face_name_align',\n",
    "    'race', 'race4',\n",
    "    'gender', 'age',\n",
    "    'race_scores_fair', 'race_scores_fair_4',\n",
    "    'gender_scores_fair', 'age_scores_fair']].to_csv(save_predictions, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
